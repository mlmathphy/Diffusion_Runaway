import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
import os
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split
from scipy.io import savemat

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print('Device:', device)

root_data = 'data/'
root_output = 'output/'
torch.cuda.empty_cache()
# Set random seed
np.random.seed(12345)
torch.manual_seed(12345)

# --- Load your data from the 3D SDE simulation ---
dim = 3  # (p, xi, r)

# Load the datasets generated by our modified 3D function
print("Loading datasets...")
exit_xx = np.load(os.path.join(root_data, 'exit_x.npy'))
exit_delta = np.load(os.path.join(root_data, 'exit_delta.npy'))

exit_x = exit_xx.copy()
exit_x[:, 0] = exit_xx[:, 0] * exit_xx[:, 1]
exit_x[:, 1] = exit_xx[:, 0] * np.sqrt(1 - exit_xx[:, 1]**2)

print(f"Original dataset sizes:")
print(f"exit_x shape: {exit_x.shape}")
print(f"exit_delta shape: {exit_delta.shape}")
print(f"Exit rate: {100 * np.mean(exit_delta == 0):.2f}%")

# Find the deterministic boundary
print("\nAnalyzing deterministic boundary...")
exit_indices = np.where(exit_delta == 0)[0]  # Where exit happens
stay_indices = np.where(exit_delta == 1)[0]  # Where particle stays

if len(exit_indices) > 0:
    min_exit_r = np.min(exit_xx[exit_indices, 2])
    print(f"Minimum r value where exit occurs: {min_exit_r:.6f}")
    
    # Check if all points below this threshold are always stay (exit_delta=1)
    below_threshold = exit_xx[:, 2] < min_exit_r
    below_threshold_exits = exit_delta[below_threshold]
    
    print(f"Points below threshold: {np.sum(below_threshold)}")
    print(f"Exit rate below threshold: {100 * np.mean(below_threshold_exits == 0):.2f}%")
    
    if np.all(below_threshold_exits == 1):
        print("✓ Confirmed: All points below threshold always stay (exit_delta=1)")
        deterministic_threshold = min_exit_r
        
        # Filter training data to only include uncertain region
        uncertain_mask = exit_xx[:, 2] >= deterministic_threshold
        print(f"Training on {np.sum(uncertain_mask)}/{len(exit_xx)} points ({100*np.sum(uncertain_mask)/len(exit_xx):.1f}%)")
        
        # Apply filter
        exit_x_filtered = exit_x[uncertain_mask]
        exit_delta_filtered = exit_delta[uncertain_mask]
        exit_xx_filtered = exit_xx[uncertain_mask]
        
        print(f"Filtered dataset - Exit rate: {100 * np.mean(exit_delta_filtered == 0):.2f}%")
        
        # Save threshold for prediction
        threshold_info = {
            'deterministic_threshold': deterministic_threshold,
            'below_threshold_value': 1.0  # Always predict 1 (stay) below threshold
        }
        np.save(os.path.join(root_data, 'deterministic_threshold.npy'), threshold_info)
        
        # Use filtered data
        exit_x = exit_x_filtered
        exit_delta = exit_delta_filtered
        exit_xx = exit_xx_filtered
        
    else:
        print("⚠ Warning: Found exits below minimum threshold - using full dataset")
        deterministic_threshold = None
else:
    print("No exits found in dataset")
    deterministic_threshold = None

# Subsample from large dataset to make training manageable
total_samples = exit_x.shape[0]
max_samples = min(2000000, total_samples)  # Use up to 500k samples
sample_indices = np.random.choice(total_samples, size=max_samples, replace=False)

X = exit_x[sample_indices]  # 3D positions
Y = exit_delta[sample_indices]  # Binary exit flags (0=exit, 1=stay)

print(f"Sampled dataset shapes: X={X.shape}, Y={Y.shape}")
print(f"Sampled exit rate: {100 * np.mean(Y == 0):.2f}%")

# exit()
# # Save for inspection
# mdic = {"loc": X, "prob": Y}
# savemat(os.path.join(root_output, "escape_prob.mat"), mdic)

# Normalize features - important for 3D physics data
mu_weight = X.mean(axis=0)
s_weight = X.std(axis=0)

# Save normalization parameters
os.makedirs(root_data, exist_ok=True)
with open(os.path.join(root_data, 'weight_mean_std2.npy'), 'wb') as f:
    np.save(f, mu_weight)
    np.save(f, s_weight)

print(f"Normalization - Mean: {mu_weight}, Std: {s_weight}")

# Apply normalization
X_normalized = (X - mu_weight) / s_weight

# Convert to PyTorch tensors
X_tensor = torch.tensor(X_normalized, dtype=torch.float32)
Y_tensor = torch.tensor(Y.reshape(-1, 1), dtype=torch.float32)

print(f"Tensor shapes: X={X_tensor.shape}, Y={Y_tensor.shape}")

# Train/Validation split
X_train, X_val, Y_train, Y_val = train_test_split(
    X_tensor, Y_tensor, test_size=0.1, random_state=123, stratify=Y
)

print(f"Training set: {X_train.shape[0]} samples")
print(f"Validation set: {X_val.shape[0]} samples")

# Create datasets and data loaders
train_dataset = TensorDataset(X_train, Y_train)
val_dataset = TensorDataset(X_val, Y_val)

# Use larger batch size for efficiency with large dataset
batch_size = int(total_samples/8)  # Increased from 4096
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2)

print(f"Number of training batches: {len(train_loader)}")
print(f"Number of validation batches: {len(val_loader)}")

def make_folder(folder):
    if not os.path.exists(folder):
        os.makedirs(folder)

def save_model(model, calibration_params=None):
    make_folder(root_output)
    filename = 'NN_3D_escape_model2'
    checkpoint = {
        'state_dict': model.state_dict(),
        'normalization': {'mean': mu_weight, 'std': s_weight},
        'dim': dim
    }
    if calibration_params is not None:
        checkpoint['calibration_A'] = calibration_params[0]
        checkpoint['calibration_B'] = calibration_params[1]
    torch.save(checkpoint, os.path.join(root_output, filename + '.pt'))
    print(f"Model saved to {os.path.join(root_output, filename + '.pt')}")

# Define Focal Loss for better rare event handling
class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, inputs, targets):
        bce_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')
        pt = torch.exp(-bce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss
        return focal_loss.mean()

# Define deeper model with dropout for 3D physics problem
class EscapeModel(nn.Module):
    def __init__(self):
        super(EscapeModel, self).__init__()
        self.dim = dim
        self.hid_size = 512  # Increased hidden size for complex 3D physics
        self.net = nn.Sequential(
            nn.Linear(self.dim, self.hid_size),
            nn.LeakyReLU(0.01),
            nn.BatchNorm1d(self.hid_size),
            nn.Dropout(0.3),
            
            nn.Linear(self.hid_size, self.hid_size),
            nn.LeakyReLU(0.01),
            nn.BatchNorm1d(self.hid_size),
            nn.Dropout(0.3),
            
            nn.Linear(self.hid_size, self.hid_size//2),
            nn.LeakyReLU(0.01),
            nn.BatchNorm1d(self.hid_size//2),
            nn.Dropout(0.2),
            
            nn.Linear(self.hid_size//2, self.hid_size//4),
            nn.LeakyReLU(0.01),
            nn.Dropout(0.1),
            
            nn.Linear(self.hid_size//4, 1)
            # No sigmoid here since we're using logits
        )
    
    def forward(self, x):
        return self.net(x)

model = EscapeModel().to(device)
print(f"Model has {sum(p.numel() for p in model.parameters())} parameters")

# Use Focal Loss instead of weighted BCE
criterion = FocalLoss(alpha=0.25, gamma=2)

optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=5, verbose=True
)

# Training loop with progress tracking
num_epochs = 50
train_losses = []
val_losses = []

print("Starting training...")
for epoch in range(num_epochs):
    # Training phase
    model.train()
    train_loss = 0.0
    train_correct = 0
    train_total = 0
    
    for batch_idx, (inputs, labels) in enumerate(train_loader):
        inputs, labels = inputs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        train_loss += loss.item() * inputs.size(0)
        
        # Calculate accuracy
        predicted = (torch.sigmoid(outputs) > 0.5).float()
        train_total += labels.size(0)
        train_correct += (predicted == labels).sum().item()
        
        if batch_idx % 100 == 0:
            print(f"Epoch {epoch}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.6f}")
    
    train_loss /= len(train_loader.dataset)
    train_acc = 100.0 * train_correct / train_total
    
    # Validation phase
    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * inputs.size(0)
            
            # Calculate accuracy
            predicted = (torch.sigmoid(outputs) > 0.5).float()
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()
    
    val_loss /= len(val_loader.dataset)
    val_acc = 100.0 * val_correct / val_total
    
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    
    scheduler.step(val_loss)
    
    print(f"Epoch {epoch+1}/{num_epochs}")
    print(f"Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.2f}%")
    print(f"Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.2f}%")
    print("-" * 50)
    
    # Save model periodically
    if (epoch + 1) % 10 == 0:
        save_model(model)

# Simple Platt scaling calibration
print("Calibrating probabilities with Platt scaling...")
model.eval()
with torch.no_grad():
    val_probs = torch.sigmoid(model(X_val.to(device))).cpu().numpy().flatten()

# Platt scaling: fit a sigmoid to map raw probabilities to calibrated ones
from scipy.optimize import minimize_scalar

def platt_scaling(probs, labels):
    """Simple Platt scaling implementation"""
    def sigmoid(x, A, B):
        return 1 / (1 + np.exp(A * x + B))
    
    def loss(params):
        A, B = params
        calibrated = sigmoid(probs, A, B)
        # Cross-entropy loss
        eps = 1e-15
        calibrated = np.clip(calibrated, eps, 1 - eps)
        return -np.mean(labels * np.log(calibrated) + (1 - labels) * np.log(1 - calibrated))
    
    # Optimize A and B
    from scipy.optimize import minimize
    result = minimize(loss, [1.0, 0.0], method='BFGS')
    return result.x

# Fit calibration parameters
A, B = platt_scaling(val_probs, Y_val.numpy().flatten())
print(f"Calibration parameters: A={A:.4f}, B={B:.4f}")

def apply_calibration(probs, A, B):
    """Apply Platt scaling calibration"""
    return 1 / (1 + np.exp(A * probs + B))

# Final model save with calibration parameters
save_model(model, (A, B))

# Function to make calibrated predictions  
def predict_calibrated(model, A, B, x):
    model.eval()
    with torch.no_grad():
        raw_probs = torch.sigmoid(model(x)).cpu().numpy().flatten()
        calibrated_probs = apply_calibration(raw_probs, A, B)
    return calibrated_probs

# Test calibration on validation set
calibrated_val_probs = predict_calibrated(model, A, B, X_val.to(device))
print(f"Raw validation probabilities - Mean: {val_probs.mean():.4f}, Std: {val_probs.std():.4f}")
print(f"Calibrated validation probabilities - Mean: {calibrated_val_probs.mean():.4f}, Std: {calibrated_val_probs.std():.4f}")
print(f"True validation rate: {Y_val.numpy().mean():.4f}")

# Plot training curves
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')

plt.subplot(1, 3, 2)
plt.plot(range(len(train_losses)), train_losses, label='Train')
plt.plot(range(len(val_losses)), val_losses, label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.yscale('log')
plt.title('Loss (Log Scale)')

# Plot calibration comparison
plt.subplot(1, 3, 3)
plt.hist(val_probs, bins=50, alpha=0.7, label='Raw Probabilities', density=True)
plt.hist(calibrated_val_probs, bins=50, alpha=0.7, label='Calibrated Probabilities', density=True)
plt.axvline(Y_val.numpy().mean(), color='red', linestyle='--', label='True Rate')
plt.xlabel('Probability')
plt.ylabel('Density')
plt.legend()
plt.title('Probability Calibration')

plt.tight_layout()
plt.savefig(os.path.join(root_output, 'training_curves_with_calibration.png'), dpi=300, bbox_inches='tight')
plt.show()

print("Training completed!")
print(f"Final train loss: {train_losses[-1]:.6f}")
print(f"Final validation loss: {val_losses[-1]:.6f}")
print("Model saved with calibrator for better probability estimates.")